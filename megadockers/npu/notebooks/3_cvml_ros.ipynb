{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2313db-cc41-4589-b2d9-4974abe55ca7",
   "metadata": {},
   "source": [
    "# Ryzen AI CVML Integration with ROS\n",
    "\n",
    "In this notebook, we'll integrate the Ryzen AI CVML library with ROS 2 to create NPU-accelerated vision nodes for robotics applications.\n",
    "\n",
    "## Goals\n",
    "\n",
    "* Learn how to integrate NPU acceleration into your own ROS projects\n",
    "* Launch CVML nodes with ROS 2\n",
    "* Visualize depth estimation and face detection outputs in ROS\n",
    "\n",
    "## References\n",
    "\n",
    "* [Writing a Simple Publisher and Subscriber (C++)](https://docs.ros.org/en/kilted/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html)\n",
    "* [Using ROS 2 Launch Files](https://docs.ros.org/en/kilted/Tutorials/Intermediate/Launch/Launch-Main.html)\n",
    "* [cv_bridge](https://github.com/ros-perception/vision_opencv/tree/ros2/cv_bridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "package-overview",
   "metadata": {},
   "source": [
    "## The `ryzen_ai_cvml` ROS Package\n",
    "\n",
    "The `ryzen_ai_cvml` package wraps the CVML C++ API into ROS 2 nodes. It provides:\n",
    "\n",
    "### Nodes\n",
    "- **depth_estimation_node**: Subscribes to image topics, publishes depth maps\n",
    "- **face_detection_node**: Detects faces and publishes bounding boxes + landmarks\n",
    "- **face_mesh_node**: Generates 3D face meshes (468 landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-package",
   "metadata": {},
   "source": [
    "## Explore the Package Structure\n",
    "\n",
    "Let's look at what's in the `ryzen_ai_cvml` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "list-package",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvml_ros/:\n",
      "CMakeLists.txt\tinclude  launch  package.xml  README.md  scripts  src\n",
      "\n",
      "cvml_ros/include:\n",
      "cvml_ros\n",
      "\n",
      "cvml_ros/include/cvml_ros:\n",
      "depth_estimation_node.hpp  face_detection_node.hpp  face_mesh_node.hpp\n",
      "\n",
      "cvml_ros/launch:\n",
      "depth_estimation.launch.py  face_detection.launch.py  face_mesh.launch.py\n",
      "\n",
      "cvml_ros/scripts:\n",
      "video_publisher.py\n",
      "\n",
      "cvml_ros/src:\n",
      "depth_estimation_node.cpp  face_detection_node.cpp  face_mesh_node.cpp\n",
      "face_detection_main.cpp    face_mesh_main.cpp\t    main.cpp\n"
     ]
    }
   ],
   "source": [
    "!ls -R cvml_ros/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "build-package",
   "metadata": {},
   "source": [
    "## Building the ROS Package\n",
    "\n",
    "If the package isn't built yet, we need to build it with colcon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "build-ros-pkg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building cvml_ros package...\n",
      "Starting >>> cvml_ros\n",
      "Finished <<< cvml_ros [0.09s]\n",
      "\n",
      "Summary: 1 package finished [0.31s]\n",
      "Build complete!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# This cell might take a few minutes\n",
    "\n",
    "cd cvml_ros\n",
    "\n",
    "# Check if already built\n",
    "if [ -d \"build\" ]; then\n",
    "    echo \"Package appears to be already built.\"\n",
    "    echo \"Skipping build. If you need to rebuild, run: colcon build --packages-select cvml_ros\"\n",
    "else\n",
    "    echo \"Building cvml_ros package...\"\n",
    "    source /opt/ros/kilted/setup.bash\n",
    "    cd ..\n",
    "    colcon build --packages-select cvml_ros\n",
    "    echo \"Build complete!\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795bad2b-446a-4683-8855-d411a33a07a4",
   "metadata": {},
   "source": [
    "## Launch Loopback Video Publisher\n",
    "\n",
    "For this part you will want to open a new jupyter terminal\n",
    "\n",
    "![](images/new_terminal.png)\n",
    "\n",
    "Copy-paste in the following:\n",
    "\n",
    "```bash\n",
    "sudo bash -c \"source install/setup.sh && \\\n",
    "              ros2 run cvml_ros video_publisher.py \\\n",
    "                --ros-args \\\n",
    "                -p video_path:=/ryzers/RyzenAI-SW/Ryzen-AI-CVML-Library/samples/video_call.mp4 \\\n",
    "                -p topic:=/camera/image_raw\"\n",
    "```\n",
    "\n",
    "You should see these messages if successful:\n",
    "```\n",
    "[INFO] [1760488629.706959565] [video_publisher]: Publishing video from: /ryzers/RyzenAI-SW/Ryzen-AI-CVML-Library/samples/video_call.mp4\n",
    "[INFO] [1760488629.707166260] [video_publisher]: Publishing to topic: /camera/image_raw\n",
    "```\n",
    "\n",
    "Let's see if ROS detects our new node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9e238a-f922-4487-8b64-19c1b96a26f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/camera/image_raw\n",
      "/parameter_events\n",
      "/rosout\n"
     ]
    }
   ],
   "source": [
    "!source install/setup.sh && ros2 topic list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e3a2d-717d-4e5d-999a-6a912f12cdfe",
   "metadata": {},
   "source": [
    "Excellent! We have a video_publisher node active in our system. Now let's use the CVML depth estimation node to subscribe to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "launch-depth",
   "metadata": {},
   "source": [
    "## Launch Depth Estimation Pipeline\n",
    "\n",
    "For this we will want yet another new terminal\n",
    "\n",
    "![](images/new_terminal.png)\n",
    "\n",
    "Now type these commands into the new terminal:\n",
    "\n",
    "```bash\n",
    "source /opt/ros/kilted/setup.bash\n",
    "source install/setup.bash\n",
    "\n",
    "sudo bash -c \"source /opt/ros/kilted/setup.bash && \\\n",
    "              source install/setup.sh && \\\n",
    "              export LD_LIBRARY_PATH=$LD_LIBRARY_PATH && \\\n",
    "              ros2 launch cvml_ros depth_estimation.launch.py\"\n",
    "```\n",
    "\n",
    "The node will subscribe to our video_publisher and publish depth maps on `/depth/image`. Once all goes well you should observe lots of output, however key lines to look out for are:\n",
    "\n",
    "```\n",
    "...\n",
    "[depth_estimation_node-1] [INFO] [1760488970.246808904] [depth_estimation_node]: Ryzen AI Depth Estimation initialized\n",
    "[depth_estimation_node-1] [INFO] [1760488970.491575724] [depth_estimation_node]: Created publisher on: /depth_estimation/depth\n",
    "[depth_estimation_node-1] [INFO] [1760488970.491899477] [depth_estimation_node]: Created subscriber on: /camera/image_raw\n",
    "[depth_estimation_node-1] [INFO] [1760488970.491906947] [depth_estimation_node]: Depth estimation node started successfully\n",
    "[depth_estimation_node-1] [INFO] [1760488970.525778512] [depth_estimation_node]: Received first image: 1920x1080\n",
    "...\n",
    "```\n",
    "\n",
    "### Check Active Topics and Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9d0a688-511b-4278-a5e8-0ebccd7717fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason when nodes run in sudo we can't see node list\n",
    "#!source install/setup.sh && ros2 node list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab65f9-24ad-466c-b66a-263ccb74363a",
   "metadata": {},
   "source": [
    "Now for the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1528e662-52a3-4c19-a837-6246e72022ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/camera/image_raw\n",
      "/depth_estimation/depth\n",
      "/parameter_events\n",
      "/rosout\n"
     ]
    }
   ],
   "source": [
    "!source install/setup.sh && ros2 topic list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddafbaf-6254-4748-ab9e-696f30ffe068",
   "metadata": {},
   "source": [
    "Also, let's make sure the NPU is actually being utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c008eee-40e5-4882-ab1b-98af3c8a81a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "[0000:c4:00.1] : NPU Strix Halo\n",
      "--------------------------------\n",
      "AIE Partitions\n",
      "  Total Memory Usage: N/A\n",
      "  Partition Index   : 0\n",
      "    Columns: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "    HW Contexts:\n",
      "      |PID                 |Ctx ID     |Submissions |Migrations  |Err  |Priority |\n",
      "      |Process Name        |Status     |Completions |Suspensions |     |GOPS     |\n",
      "      |Memory Usage        |Instr BO   |            |            |     |FPS      |\n",
      "      |                    |           |            |            |     |Latency  |\n",
      "      |====================|===========|============|============|=====|=========|\n",
      "      |652412              |1          |5653        |0           |0    |Normal   |\n",
      "      |N/A                 |Active     |5653        |28          |     |9        |\n",
      "      |N/A                 |1712 KB    |            |            |     |N/A      |\n",
      "      |                    |           |            |            |     |N/A      |\n",
      "      |--------------------|-----------|------------|------------|-----|---------|\n"
     ]
    }
   ],
   "source": [
    "!sudo /opt/xilinx/xrt/bin/xrt-smi examine --report aie-partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aca38e-128c-47c9-a987-5d5f7ce2c0f3",
   "metadata": {},
   "source": [
    "Great, now we have a mp4 -> video_publisher -> depth_estimation pipeline! What are we missing? We need to visualize the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6ba99-2b1f-4e01-b947-e07212f5d0ae",
   "metadata": {},
   "source": [
    "## Visualize the Pipeline\n",
    "\n",
    "```bash\n",
    "sudo bash -c \"source install/setup.sh && \\\n",
    "              ros2 run web_video_server web_video_server --ros-args -p port:=8080 -p address:=0.0.0.0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd97301-347d-4e29-ae2e-7794184a8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/camera/image_raw\n",
      "/depth_estimation/depth\n",
      "/parameter_events\n",
      "/rosout\n"
     ]
    }
   ],
   "source": [
    "!source install/setup.sh && ros2 topic list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ee5410-24a1-4c2f-9ae1-e061811653bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63cb15097ee414fa48664faa6b3b0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f763710637b4a2082f5b836db565f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Refresh Images', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "from ipywidgets import Button, Output\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "out = Output()\n",
    "display(out)\n",
    "\n",
    "def update_display(b=None):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        try:\n",
    "            camera = requests.get('http://localhost:8080/snapshot?topic=/camera/image_raw', timeout=3).content\n",
    "            depth = requests.get('http://localhost:8080/snapshot?topic=/depth_estimation/depth', timeout=3).content\n",
    "            \n",
    "            cam_b64 = base64.b64encode(camera).decode()\n",
    "            depth_b64 = base64.b64encode(depth).decode()\n",
    "            \n",
    "            display(HTML(f'''\n",
    "            <div style=\"display: flex; gap: 20px;\">\n",
    "                <div>\n",
    "                    <h3>Camera</h3>\n",
    "                    <img src=\"data:image/jpeg;base64,{cam_b64}\" width=\"480\">\n",
    "                </div>\n",
    "                <div>\n",
    "                    <h3>Depth (NPU)</h3>\n",
    "                    <img src=\"data:image/jpeg;base64,{depth_b64}\" width=\"480\">\n",
    "                </div>\n",
    "            </div>\n",
    "            '''))\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "button = Button(description=\"Refresh Images\")\n",
    "button.on_click(update_display)\n",
    "display(button)\n",
    "update_display()  # Initial display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-takeaways",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Integration Pattern\n",
    "\n",
    "1. **CVML Context** → Create and configure backend\n",
    "2. **CVML Feature** → Initialize the vision feature (depth, face, etc.)\n",
    "3. **ROS Subscriber** → Receive image messages\n",
    "4. **cv_bridge** → Convert between ROS and OpenCV formats\n",
    "5. **CVML Processing** → NPU-accelerated inference\n",
    "6. **ROS Publisher** → Publish results\n",
    "\n",
    "### Benefits of NPU in ROS\n",
    "\n",
    "- **Power Efficient**: Lower power draw compared to GPU/CPU\n",
    "- **Dedicated Hardware**: Frees up CPU/GPU for other tasks\n",
    "- **Real-time Performance**: ~30 FPS for depth estimation\n",
    "- **Easy Integration**: Same ROS patterns as any other vision node\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "1. **Backend Selection**: Use parameters to allow runtime backend switching\n",
    "2. **Error Handling**: Check NPU availability, handle fallback to CPU\n",
    "3. **Performance Monitoring**: Use `xrt-smi` to verify NPU utilization\n",
    "4. **Resource Management**: Properly release CVML contexts on shutdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You've now learned how to:\n",
    "- ✅ Validate and use the NPU with `xrt-smi`\n",
    "- ✅ Run CVML samples on different backends\n",
    "- ✅ Integrate CVML with ROS 2 for robotics applications\n",
    "\n",
    "### Further Exploration\n",
    "\n",
    "- Try different CVML features (face mesh, pose estimation)\n",
    "- Create custom ROS nodes with CVML integration\n",
    "- Combine multiple CVML features in a single pipeline\n",
    "- Benchmark NPU vs GPU vs CPU for your specific workloads\n",
    "- Build custom NPU applications with MLIR-AIE (advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "footer",
   "metadata": {},
   "source": [
    "---\n",
    "Copyright© 2025 AMD, Inc SPDX-License-Identifier: MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
