{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2313db-cc41-4589-b2d9-4974abe55ca7",
   "metadata": {},
   "source": [
    "# ROS Integration\n",
    "\n",
    "\n",
    "## Goals\n",
    "\n",
    "* Run a local VLM as a service node using ROS2 Python RCL\n",
    "\n",
    "## References\n",
    "\n",
    "* [Understanding Services](https://docs.ros.org/en/kilted/Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Services/Understanding-ROS2-Services.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5nfxw2y2m",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook demonstrates integrating a Vision Language Model (VLM) with ROS2 using llama.cpp as the inference backend.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. **llama.cpp server** running with a VLM model (e.g., LLaVA, BakLLaVA)\n",
    "2. **ROS2** environment sourced\n",
    "3. **vlm_ros package** built and sourced\n",
    "\n",
    "### Architecture\n",
    "\n",
    "- **llama.cpp server**: Runs the VLM model and exposes HTTP API (port 8080)\n",
    "- **vlm_service node**: ROS2 node that subscribes to camera images and queries the VLM\n",
    "- **Test script**: Python script to publish test images and receive VLM responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oon1an65zn",
   "metadata": {},
   "source": [
    "## Start llama.cpp Server\n",
    "\n",
    "**In a separate terminal**, start the llama.cpp server with a VLM model:\n",
    "\n",
    "```bash\n",
    "# Example: Download and run a VLM model\n",
    "export PATH=/ryzers/llamacpp/build/bin/:$PATH\n",
    "llama-server -hf ggml-org/SmolVLM-500M-Instruct-GGUF \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8080\n",
    "```\n",
    "\n",
    "Wait until you see \"HTTP server listening\" before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c424a6e-d3fb-4231-b7bd-7e351a2ba3fc",
   "metadata": {},
   "source": [
    "## Try OpenAI API server directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a743328e-59ae-4842-80ed-c64575792876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Response: \n",
      "\n",
      "In the center of the image is a dark blue oval. Inside the oval is a light blue circle with a dark blue semi-transparent triangle. Inside the triangle is a light blue semi-transparent circle with a dark blue semi-transparent triangle.\n",
      "\n",
      "The image is not realistic. There is no light blue circle in the image. The objects are not made of material. There is no background.\n",
      "\n",
      "The image is a representation of an abstract thought. The shape of the oval is reminiscent of a mathematical equation, such as the Pythagorean theorem. The triangle and circle are geometric shapes, and the light blue circle\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "import cv2\n",
    "\n",
    "# Load and encode an image\n",
    "img = cv2.imread('/ryzers/notebooks/toucan.jpg')\n",
    "_, buffer = cv2.imencode('.jpg', img)\n",
    "img_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "# Test the llama.cpp server\n",
    "payload = {\n",
    "  \"prompt\": \"Describe what you see in this image.\",\n",
    "  \"image_data\": [{\"data\": img_base64, \"id\": 1}],\n",
    "  \"n_predict\": 128\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "  'http://localhost:8080/completion',\n",
    "  json=payload,\n",
    "  timeout=30\n",
    ")\n",
    "\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(f\"Response: {response.json()['content']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xmer6c51u1r",
   "metadata": {},
   "source": [
    "## Build the ROS Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48v7cqpall7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting >>> vlm_ros\n",
      "Finished <<< vlm_ros [0.60s]\n",
      "\n",
      "Summary: 1 package finished [0.67s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /opt/ros/kilted/setup.bash\n",
    "\n",
    "# Build the vlm_ros package\n",
    "cd /ryzers/notebooks/vlm_ros\n",
    "colcon build --symlink-install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x39wtvqpvmh",
   "metadata": {},
   "source": [
    "## Start the VLM Service Node\n",
    "\n",
    "Run the VLM service node in the background:\n",
    "\n",
    "```bash\n",
    "source /opt/ros/kilted/setup.bash\n",
    "source /ryzers/notebooks/vlm_ros/install/setup.bash\n",
    "ros2 run vlm_ros vlm_service\n",
    "```\n",
    "\n",
    "You should see this output:\n",
    "\n",
    "```\n",
    "[INFO] [1760575146.024196594] [vlm_service]: VLM Service started, connecting to http://localhost:8080\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f21n2azupo",
   "metadata": {},
   "source": [
    "## Test with a Sample Image\n",
    "\n",
    "Create a test script to publish an image and receive VLM responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7qm76p1xo4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLM tester node initialized\n"
     ]
    }
   ],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image\n",
    "from std_msgs.msg import String\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class VLMTester(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('vlm_tester')\n",
    "        self.image_pub = self.create_publisher(Image, 'camera/image', 10)\n",
    "        self.response_sub = self.create_subscription(String, 'vlm/response', self.response_callback, 10)\n",
    "        self.bridge = CvBridge()\n",
    "        self.latest_response = None\n",
    "        \n",
    "    def response_callback(self, msg):\n",
    "        self.latest_response = msg.data\n",
    "        print(f\"\\nVLM Response: {msg.data}\\n\")\n",
    "        \n",
    "    def publish_test_image(self, image_path):\n",
    "        # Load and publish image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Could not load image: {image_path}\")\n",
    "            return\n",
    "            \n",
    "        msg = self.bridge.cv2_to_imgmsg(img, encoding='bgr8')\n",
    "        self.image_pub.publish(msg)\n",
    "        print(f\"Published image: {image_path}\")\n",
    "\n",
    "# Initialize ROS\n",
    "rclpy.init()\n",
    "tester = VLMTester()\n",
    "print(\"VLM tester node initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neas4wx6t7",
   "metadata": {},
   "source": [
    "### Publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bvgsjmxc3j4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published image: /ryzers/notebooks/toucan.jpg\n",
      "\n",
      "VLM Response:  I can give you feedback and suggestions to improve the writing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Publish a test image\n",
    "tester.publish_test_image('/ryzers/notebooks/toucan.jpg')\n",
    "\n",
    "# Spin to receive responses\n",
    "import time\n",
    "for _ in range(10):  # Wait up to 5 seconds for response\n",
    "    rclpy.spin_once(tester, timeout_sec=0.5)\n",
    "    if tester.latest_response:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b285bb33-051c-4edb-bb43-14e4efa00fde",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "CopyrightÂ© 2025 AMD, Inc SPDX-License-Identifier: MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
