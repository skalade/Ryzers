{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c4c387-f0b9-4379-8ad4-12ae1895ad3c",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Robot Policies\n",
    "\n",
    "<img src=\"images/gpu.png\" width=\"600\" height=\"300\">\n",
    "\n",
    "In this tutorial we will cover the necessary tools you need to inspect your AMD GPU usage. You will learn how to run local Large Language Models (LLMs) and Vision Language Models (VLMs) with projects like `llama.cpp`. Additionally we'll walk you through running robot policy models specifically tailored for robotics and we will show you how to integrate an AMD system.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. [AMD GPU Utilities](1_gpu_utilities.ipynb) - first we will walk through the driver stack and tools like `rocm-smi` and `amdgpu_top` to inspect GPU utilization.\n",
    "2. [Running LLMs](2_running_llms.ipynb) - you will learn how to run state-of-the-art LLMs like Qwen3 and Llama3.2 all locally on the Strix Halo.\n",
    "3. [VLMs and ROS Integration](3_vlm_ros_integration.ipynb) - we'll show you how to integrate VLMs into your ROS application.\n",
    "4. [Robot Policies](4_robot_policies.ipynb) - you will learn how Vision-Language-Action (VLA) models work, what makes them different and how to run a foundational model like SmolVLA.\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "After you've completed this set of notebooks you will be well equipped to run state-of-the-art AI applications on your local Ryzen AI MAX+ machine, debug using available ROCm utilities and integrate any AI model into your ROS projects.\n",
    "\n",
    "**Continue to:** [1_gpu_utilities.ipynb](1_gpu_utilities.ipynb)\n",
    "\n",
    "---\n",
    "CopyrightÂ© 2025 AMD, Inc SPDX-License-Identifier: MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83a29c-ed86-42c8-98aa-dd28fdf82050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
